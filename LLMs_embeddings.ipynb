{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "972c8dd9b9a3408ca31e0c68aab8f836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6ad3a6b2a1d4393a50816830af25c4a",
              "IPY_MODEL_53d58ab23a024609a8d8abce5f52fe96",
              "IPY_MODEL_1b2234d77b7542f3a973c34b84bbfd22"
            ],
            "layout": "IPY_MODEL_8246aba6e8b6444cb5d8180df4156feb"
          }
        },
        "e6ad3a6b2a1d4393a50816830af25c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7908ddfe803d4dee93110b04fde22814",
            "placeholder": "​",
            "style": "IPY_MODEL_3165760cd3d549f5bcedff8bc0986907",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "53d58ab23a024609a8d8abce5f52fe96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f1a157775547e0878d31b3b34587ec",
            "max": 2836623617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_994bd5a57c1a40b0be6b8bff08b9fc0f",
            "value": 2836623617
          }
        },
        "1b2234d77b7542f3a973c34b84bbfd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f20fbf7c8a49599c1ce21fc29c66d2",
            "placeholder": "​",
            "style": "IPY_MODEL_e545aa91da7e43e28fc3f930ba567af3",
            "value": " 2.84G/2.84G [00:26&lt;00:00, 178MB/s]"
          }
        },
        "8246aba6e8b6444cb5d8180df4156feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7908ddfe803d4dee93110b04fde22814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3165760cd3d549f5bcedff8bc0986907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4f1a157775547e0878d31b3b34587ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "994bd5a57c1a40b0be6b8bff08b9fc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79f20fbf7c8a49599c1ce21fc29c66d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e545aa91da7e43e28fc3f930ba567af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aac83d7efbba4b6d9c72777e695ec9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b3fe87fcbb47c89ed4514dc144ce19",
              "IPY_MODEL_fa31debd8dde442797716358fbb98127",
              "IPY_MODEL_c25240d67da848218707bc1137d440f3"
            ],
            "layout": "IPY_MODEL_2d8aa501f2764fb08140b9366e78c26a"
          }
        },
        "49b3fe87fcbb47c89ed4514dc144ce19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac8c12253874cf284708b783869bb96",
            "placeholder": "​",
            "style": "IPY_MODEL_7aba319309554d13bc7037ee38e66fc6",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "fa31debd8dde442797716358fbb98127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb67b46b2e246e3821c6830a7b88643",
            "max": 69,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8fb0237dfa54ceca3bc6f7c5c4be814",
            "value": 69
          }
        },
        "c25240d67da848218707bc1137d440f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a6d2c9b5884ed89b4756aa8ff0e781",
            "placeholder": "​",
            "style": "IPY_MODEL_22c6d6e9d5fc4582bec3bd47d5202a36",
            "value": " 69.0/69.0 [00:00&lt;00:00, 3.86kB/s]"
          }
        },
        "2d8aa501f2764fb08140b9366e78c26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac8c12253874cf284708b783869bb96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aba319309554d13bc7037ee38e66fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb67b46b2e246e3821c6830a7b88643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8fb0237dfa54ceca3bc6f7c5c4be814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a6d2c9b5884ed89b4756aa8ff0e781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c6d6e9d5fc4582bec3bd47d5202a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daka13/HowLLMsWork/blob/main/LLMs_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeJzAFZ7H5DX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect the embedding layers of LLMs\n",
        "\n",
        "All LLMs have an initial layer of *embeddings* that maps tokens to vectors. In this mini-project you will practice extracting the embedding layer from an LLM, and"
      ],
      "metadata": {
        "id": "ocKeGgJYt1gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "972c8dd9b9a3408ca31e0c68aab8f836",
            "e6ad3a6b2a1d4393a50816830af25c4a",
            "53d58ab23a024609a8d8abce5f52fe96",
            "1b2234d77b7542f3a973c34b84bbfd22",
            "8246aba6e8b6444cb5d8180df4156feb",
            "7908ddfe803d4dee93110b04fde22814",
            "3165760cd3d549f5bcedff8bc0986907",
            "b4f1a157775547e0878d31b3b34587ec",
            "994bd5a57c1a40b0be6b8bff08b9fc0f",
            "79f20fbf7c8a49599c1ce21fc29c66d2",
            "e545aa91da7e43e28fc3f930ba567af3",
            "aac83d7efbba4b6d9c72777e695ec9c6",
            "49b3fe87fcbb47c89ed4514dc144ce19",
            "fa31debd8dde442797716358fbb98127",
            "c25240d67da848218707bc1137d440f3",
            "2d8aa501f2764fb08140b9366e78c26a",
            "3ac8c12253874cf284708b783869bb96",
            "7aba319309554d13bc7037ee38e66fc6",
            "feb67b46b2e246e3821c6830a7b88643",
            "d8fb0237dfa54ceca3bc6f7c5c4be814",
            "a5a6d2c9b5884ed89b4756aa8ff0e781",
            "22c6d6e9d5fc4582bec3bd47d5202a36"
          ]
        },
        "id": "UOQXMDeoIOKg",
        "outputId": "e04e622b-cdc8-4aaa-d39a-1abedc1659f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/2.84G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "972c8dd9b9a3408ca31e0c68aab8f836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aac83d7efbba4b6d9c72777e695ec9c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the model architecture to determine where the initial embedding layer is. It will be by far the largest dimension, mapping the size of the vocabulary to the internal dimension."
      ],
      "metadata": {
        "id": "wXl2xU7eXQz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpDNNQaGXfOS",
        "outputId": "eaed6929-5cbe-4849-f506-837eda3561c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixFormerSequentialForCausalLM(\n",
              "  (layers): Sequential(\n",
              "    (0): Embedding(\n",
              "      (wte): Embedding(51200, 2048)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (2): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (3): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (4): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (5): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (6): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (7): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (8): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (9): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (10): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (11): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (12): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (13): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (14): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (15): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (16): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (17): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (18): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (19): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (20): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (21): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (22): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (23): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (24): ParallelBlock(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      (mixer): MHA(\n",
              "        (rotary_emb): RotaryEmbedding()\n",
              "        (Wqkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (inner_attn): SelfAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (inner_cross_attn): CrossAttention(\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        (act): NewGELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (25): CausalLMHead(\n",
              "      (ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (linear): Linear(in_features=2048, out_features=51200, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (loss): CausalLMLoss(\n",
              "    (loss_fct): CrossEntropyLoss()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.layers[0].wte.weight.data.numpy()"
      ],
      "metadata": {
        "id": "JsFV3w32JrXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab = np.empty(tokenizer.vocab_size, dtype=object)\n",
        "for i in range(tokenizer.vocab_size):\n",
        "  vocab[i] = tokenizer.decode(i)"
      ],
      "metadata": {
        "id": "WnDLP2xHKM5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the vocabulary according to the vector provided, print the words at both extremes\n",
        "def sort_words(v, n=10):\n",
        "    words = sorted(zip(v, vocab), reverse=True)\n",
        "    output = [[\"{}\".format(word) for score, word in words[:n]], \"...\",\n",
        "            [\"{}\".format(word) for score, word in words[-n:]]]\n",
        "    return output\n",
        "\n",
        "def cosine_sim(w_id):\n",
        "  norms = np.linalg.norm(embeddings, axis=1)\n",
        "  inner_products = embeddings @ embeddings[w_id,:]\n",
        "  inner_products /= (norms * norms[w_id])\n",
        "  return inner_products"
      ],
      "metadata": {
        "id": "RoRpkM6Ig9rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[5500:5700]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5C6v_5NhPZT",
        "outputId": "333a876c-b58b-4581-befc-b472d17aefa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['uts', ' Each', ' Jeff', ' stress', ' accounts', ' guarant',\n",
              "       ' Ann', 'edia', ' honest', ' tree', ' African', ' Bush', '},',\n",
              "       ' sch', ' Only', ' fif', 'igan', ' exercise', ' Exp',\n",
              "       ' scientists', ' legislation', ' Work', ' Spr', 'Â', ' Human',\n",
              "       ' �', ' survey', ' rich', 'rip', ' maintain', ' flo',\n",
              "       ' leadership', 'stream', ' Islamic', ' 01', ' College', ' magic',\n",
              "       ' Prime', ' figures', '2017', 'inder', 'xual', ' Dead',\n",
              "       ' absolutely', ' fourth', ' presented', 'respond', 'rible',\n",
              "       ' alcohol', 'ato', ' DE', 'porary', ' grab', ' vari', ' quant',\n",
              "       ' Photo', ' plus', 'rick', 'arks', ' alternative', ' pil',\n",
              "       ' approx', 'that', ' objects', ' Ro', ' Android', ' significantly',\n",
              "       ' Road', 'kay', 'Read', 'avor', ' acknow', ' HD', ' Sing', 'Or',\n",
              "       ' Mont', ' uns', 'prof', ' negoti', ' Arch', 'iki', ' television',\n",
              "       ' Jewish', ' committee', ' motor', ' appearance', ' sitting',\n",
              "       ' strike', ' Down', 'comp', ' Hist', ' fold', 'acement', ' Louis',\n",
              "       ' belong', ' •', ' mort', ' prepared', ' 64', ' Master', ' indeed',\n",
              "       ' Den', ' rent', 'TA', 'ourney', 'arc', 'Su', '97', ' advice',\n",
              "       ' changing', ' listed', ' launched', 'isation', ' Peter', 'ishes',\n",
              "       ' lived', ' Mel', ' Supreme', ' Federal', ' );', 'ructure',\n",
              "       ' sets', ' philos', 'uous', ' \\xa0', ' applied', ' NOT',\n",
              "       ' housing', ' Mount', ' odd', ' sust', 'DA', 'fficient', '?',\n",
              "       'olved', ' powers', ' thr', ' remaining', ' Water', 'LC',\n",
              "       ' causes', 'の', ' manner', 'ads', ' suggests', ' ends', 'standing',\n",
              "       'fig', ' Dun', 'idth', ' gay', ' termin', ' Angeles', 'MS',\n",
              "       ' scientific', ' coal', 'apers', 'bar', ' Thomas', ' sym', ' Run',\n",
              "       'this', 'PC', 'igrants', ' minute', ' District', 'cellent',\n",
              "       ' leaves', ' completed', 'amin', ' focused', ' monitor',\n",
              "       ' vehicles', 'MA', ' Mass', ' Grand', ' affected', 'itutional',\n",
              "       ' construct', ' follows', ' ton', 'reens', ' homes', ' Ext',\n",
              "       ' Level', 'rast', ' Ir', ' elim', ' largely', ' Joe', ' votes',\n",
              "       'alls', ' businesses', ' Foundation', ' Central', ' yards',\n",
              "       ' materials', 'ulner', ' guide', ' closer'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\" College\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy75YlzTh9qg",
        "outputId": "33cee04a-e5a3-40b5-c556-37caa9a344af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5535]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_words(cosine_sim(5535))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh5ZHYuiiAwZ",
        "outputId": "a3907731-2674-45b3-a200-349c52589dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[' College',\n",
              "  ' college',\n",
              "  'College',\n",
              "  ' colleges',\n",
              "  'college',\n",
              "  ' Colleges',\n",
              "  ' University',\n",
              "  ' School',\n",
              "  ' university',\n",
              "  'University'],\n",
              " '...',\n",
              " [' skirm',\n",
              "  ' benign',\n",
              "  'Thor',\n",
              "  ' muttered',\n",
              "  'Tact',\n",
              "  'pull',\n",
              "  ' puzz',\n",
              "  '\\x03',\n",
              "  'ispers',\n",
              "  ' ruth']]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_words(np.linalg.norm(embeddings, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-RYl1R_0hHTs",
        "outputId": "bfa89ebb-5c21-481f-be44-8b4148d89525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'� �  TheNitrome  guiIcon  TheNitromeFan  guiActive  unfocusedRange channelAvailability GoldMagikarp  srfN ... -  by  that  as  on  to  for  from  with  in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}